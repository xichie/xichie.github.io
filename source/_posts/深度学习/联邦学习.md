---
title: 联邦学习
tags:
  - c语言
  - 算法
  - PAT
categories:
  - 深度学习
toc: true
comments: true
mathjax: true
description: 隐藏后续内容
abbrlink: 3977b5c
date: 2022-03-10 20:49:49
---

# 为什么要联邦学习
![在这里插入图片描述](https://img-blog.csdnimg.cn/37cc1a35b2294f86b1215874fd205298.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAd2FybS0=,size_20,color_FFFFFF,t_70,g_se,x_16)

已有的数据中心学习架构，存在成本高昂，数据隐私和安全问题。在用户将数据上传到数据中心的过程中，敏感数据极易受到泄露、攻击和网络的影响。比如，万豪（2018年受影响的客户数为5亿）和eBay（2014年受影响的用户数为1.45亿）。在这种情况下，欧盟实施了一项名为《通用数据保护条例》（GDPR）的新法规，通过设置规则、限制数据共享和存储来保护个人数据。
基于上述的这些规则，On-site ML和FL已经成为替代数据中心的解决方案
<!--more-->

![在这里插入图片描述](https://img-blog.csdnimg.cn/8e478f6ec5784a3db69c7817feb6835e.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAd2FybS0=,size_20,color_FFFFFF,t_70,g_se,x_16)

## 基于云（集中式）的学习：
### 存在的问题

- 用户数据上传到云上共享，用户很容易泄露
- 延迟，数据可以传输数百甚至数千英里才能到达云端
- 成本，数据通过网络传输是需要成本的
### 优点
## on-site 学习：
将ML任务从云端转移到用户设备上，中央服务器将预训练或者通用的ML模型分发给用户，然后每个用户使用本地数据进行训练，对其进行个性化的定制。设备上的智能已被应用于许多应用，如皮肤癌检测、医疗应用、智能教室、神经网络辅助服务等
### 优点

- 数据不离开本地，保护了用户的隐私安全
### 存在的问题

- 这种方式构建各自的模型不能获得其它方数据和经验
## 联邦学习
谷歌研究人员在2016年创造了FL，自那以后，它在学术界和工业界都获得了蓬勃发展，席卷全球。它旨在建立一个基于分布数据集的联邦学习模型，在保护数据隐私的前提下实现由多个参与者的本地数据训练出统一的机器学习模型。在FL中，原始数据保存在终端用户设备上，这些设备合作训练联合模型。中央服务器只负责接受并聚合各个用户设备的模型更新和结果，然后再将聚合后的模型发送给各个用户，从而使各个用户之间可以共享知识。
FL首先在谷歌的Android键盘Gboard上测试，当Gboard在屏幕上显示一些建议时，根据用户的行为，进行本地学习。然后，综合不同用户的行为，增强预测的结果。
目前已有的开源框架有：tensorflow federated（TFF），federated AI technology enabler（FATE）， PySyft, PaddleFL, and Clara training framework。
在研究领域，主要有图像分类和NLP。常用的数据集，MNIST和CIFAR。
### 学习过程
![在这里插入图片描述](https://img-blog.csdnimg.cn/3c89a65f49474315b15a2fbcd2c786c8.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAd2FybS0=,size_20,color_FFFFFF,t_70,g_se,x_16)


1. 中央服务器根据客户端的状态（充电，空闲，wifi连接状态）选择一些客户端。
1. 被选定的客户端，从中央服务器下载当前的模型参数或权重，使用这些权重初始化本地的模型
1. 客户端使用本地数据使用SGD算法优化模型，为了降低通信成本，客户端会执行多次SGD算法。
1. 客户端训练完成后，将优化后的参数发送给中央服务器。客户端可能由于连接不良、计算资源有限、大量培训数据等原因，在培训或参数传输阶段退出。因此，会报告中央服务器无法处理的故障客户端的百分比，并根据收到的更新数量继续处理该过程。如果及时报告的客户数量不足，则放弃本轮的更新。
1. 中央服务器在根据客户的数据集大小对其进行加权后，聚合所有客户端的更新，产生了一个新的共享模型。
# 联邦学习的挑战
为什么联邦学习不属于典型的分布式学习，主要由于以下的挑战和特性：

- Non-IID数据：不同客户端的数据分布是不同的，并且之间可能会有依赖性。
- 不平衡数据：不同客户端的数据量有差距
- 大规模分布的数据 ：客户端的数量大，可能大于每个客户端平均样本的数量
- 设备连接不可靠：大多数情况下，客户端的连接速度缓慢、有限、昂贵且不可用，大大减少了可用连接的数量。此外，在可用的客户端中，由于计算能力不同，许多客户端可能无法参与每一轮学习。 
- 设备内存有限：会有大量的物联网/移动设备参与训练，这些设备内存有限
- 中毒袭击：客户端的匿名性可能会让攻击者表现得像普通用户，并被选中参与FL。因此，攻击者可以在训练阶段通过提供有毒数据来使模型预测不准确。 

# 联邦学习的发展

![在这里插入图片描述](https://img-blog.csdnimg.cn/17d1a1d943414003b88ff346cda0596b.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAd2FybS0=,size_20,color_FFFFFF,t_70,g_se,x_16)


## 系统模型和设计
![在这里插入图片描述](https://img-blog.csdnimg.cn/d59c4ce486c94c4e907e69968690e886.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAd2FybS0=,size_20,color_FFFFFF,t_70,g_se,x_16)

### 通信成本
FL在训练过程中，中央服务器和客户端之间需要多次通信。为了优化通信，已经有了许多的研究工作。

- Konecny等提出了两种方式。一种是结构化更新，通过low rank将模型的参数分成两个矩阵，一个是固定的，另一个才会发送给中央服务器。此外，在通信过程中，只发送非零值而不是整个矩阵。第二种是草图更新（stetched update）。它需要传递所有的模型参数，在发送给中央服务器之前以有损的方式进行压缩。在100台设备上测试模型，每个设备在图像分类任务中训练500个示例。结果显示上传通信量减少。
- [43]中介绍了一种通信成本最小化的方法，旨在减少服务器和客户端生成模型的大小。首先，服务器使用federated dropout技术生成更小的子模型和更少的参数。然后，在服务器端对生成的模型执行有损压缩，并将其发送到客户端，客户端解压后开始训练。最后，客户端更新就会被无损压缩并发送到服务器，服务器进行解压缩然后进行聚合。
- [46]提出了一个增强的FL框架，不仅降低了通信成本，还提高了模型的准确性。通过构建异步策略降低通信成本，允许将深层神经网络的深层和浅层分离，当客户端在全局模型表现更好时，更频繁的发送浅层的参数。另一方面， 通过在聚合中考虑在前几轮中训练的模型，而不是仅在进行中的一轮中训练的模型，提高了模型的准确性。

**总结:** 如果完全按照FL的机制在每轮中更新整个模型参数，在分布式环境中，由于参与设备众多，网络带宽有限，通信成为了FL的主要瓶颈。 
### 客户端选择
在典型的FL中选择客户端时，只考虑正在充电、空闲和WiFi设备。因此，在这些设备中，确定一个随机数以发起与它们的通信并记录它们。然而，在处理通信和计算资源方面的**异构**客户端时，仅依赖这些标准会带来许多缺点，例如训练时间长。为了解决这些问题，很少有人提出工作。
### 优化和聚合算法
FL的目标是本地训练模型，然后在服务器上聚合模型，经过多轮更新得到一个高质量的全局模型。

- [3]提出了FedAvg算法，它将训练过程分为多个回合，每个回合选择固定数量的客户端对本地数据进行学习，然后上传至服务器，对所有的客户端模型加权平均得到全局的模型。
- 联邦学习完全依赖于客户数据的均匀分布，会导致模型会偏向于特定客户。Mohri等[54]人提出了一个框架，从模型聚合和模型优化两个方便解决了该问题。
- Liu等[55]提出了一种分层联邦平均算法，在边缘服务器上进行多个本地聚合，然后将本地聚合后的模型发送到中央服务器进行全局聚合。结果证明，通过使用较少的边缘和更多的全局聚合，可以减少通信次数。

**总结：** 由于FL中的通信比计算要昂贵得多，因此优化和聚合算法对于最大限度地减少轮次、快速收敛模型和不给主干网造成负担至关重要。
### Non-IID数据
由于数据是Non-IID的，在使用SGD优化模型时，会使模型产生偏差。

- Zhao等人[58]解决了Non-IID数据导致的准确性下降的问题。客户端共享一组类别均匀分布的小数据来提高准确性，此外客户端也会使用本地的私有数据进行训练。在CIFAR-10上进行了实验，结果表明，仅使用5%的共享数据，准确率就提高了近30%。 
- [42]提出了Hybrid-FL。为客户端提供了一些激励措施，鼓励它们将数据上传到服务器，这类客户端的数量不超过总数的1%。随后，服务器对收集的数据进行训练，形成一个模型，然后其与客户端上传的模型进行聚合。数据上传客户端、客户端选择和模型上传客户端都是基于启发式算法确定的。
- [59]指出，当在分布式环境上执行FL时，FL面临两个挑战，即统计和系统。当需要从不同节点的非IID分布式数据中训练模型时，会出现统计挑战。在系统挑战方面，由于贡献的设备在通信、存储和计算方面具有不平衡的数据和不同的容量，这导致了一些容错和丢失。
### 激励措施
虽然现有的方法侧重于优化不同的FL方面，但很少有人考虑到客户不愿意参加训练或选择低质量模型更新的客户。如果服务器选择了一些客户端，它们往往会因有限的计算和通信能力而浪费资源。[61]通过基于契约理论设计一种激励机制来解决这一问题，该机制可以激励用户在FL中做出贡献。因此，客户x的数据质量越高，给予x的奖励就越多。

**总结**：在典型的FL中，假设服务器选择的所有客户端都始终可用。然而，这种乐观的假设并不能反映现实世界的情况。相当多的设备很可能在整个过程中退出，甚至由于资源成本和限制而拒绝加入。此外，为了更快地聚合全局模型，非常需要鼓励客户端提供高质量的数据。因此，提出了基于激励的方法来解决这些问题。

# FL的应用

- Gboard应用
- 医疗健康
- 物联网系统
- 边缘计算
- 智慧交通
- 推荐系统
- 网络安全

# FL的隐私和安全
尽管FL的出现就是通过防止数据共享来实现严格的隐私保护，但与隐私和安全相关的新挑战已经出现。最近的研究表明，模型更新的传输仍然会泄露客户端敏感信息。
![在这里插入图片描述](https://img-blog.csdnimg.cn/62c7173260a74785baf0f7e6724bb130.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAd2FybS0=,size_20,color_FFFFFF,t_70,g_se,x_16)


对上述隐私问题的保护，已有的研究主要解决方法

- 加密协议和差分隐私
- 安全多方计算（Secure Multiparty Computation, SMC）

# 参考资料

[1]. S. Abdulrahman, H. Tout, H. Ould-Slimane, A. Mourad, C. Talhi and M. Guizani, “A Survey on Federated Learning: The Journey From Centralized to Distributed On-Site Learning and Beyond,” in IEEE Internet of Things Journal, vol. 8, no. 7, pp. 5476-5497, 1 April1, 2021, doi: 10.1109/JIOT.2020.3030072.

[2]. 王树森. https://www.youtube.com/watch v=STxtRucv_zo&list=PLvOO0btloRns6egXueiRju4DXQjNRJQd5&index=4







































